{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: seaborn in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 3)) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 4)) (3.10.0)\n",
      "Requirement already satisfied: gensim in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 5)) (4.3.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 6)) (3.9.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 7)) (2.18.0)\n",
      "Requirement already satisfied: torch in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: torchtext==0.15.2 in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 9)) (0.15.2)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 10)) (1.6.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: keras in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 12)) (3.8.0)\n",
      "Requirement already satisfied: keras_balanced_batch_generator in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 13)) (0.0.3)\n",
      "Requirement already satisfied: ipython in c:\\users\\charl\\appdata\\roaming\\python\\python310\\site-packages (from -r Requirements.txt (line 14)) (8.32.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 15)) (3.8.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tranformers (from versions: none)\n",
      "ERROR: No matching distribution found for tranformers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "%pip install -r Requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean PolitiFact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(r'Datasets\\PolitiFact\\PolitiFact.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verdict</th>\n",
       "      <th>statement_originator</th>\n",
       "      <th>statement</th>\n",
       "      <th>statement_date</th>\n",
       "      <th>statement_source</th>\n",
       "      <th>factchecker</th>\n",
       "      <th>factcheck_date</th>\n",
       "      <th>factcheck_analysis_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>John McCain opposed bankruptcy protections for...</td>\n",
       "      <td>6/11/2008</td>\n",
       "      <td>speech</td>\n",
       "      <td>Adriel Bettelheim</td>\n",
       "      <td>6/16/2008</td>\n",
       "      <td>https://www.politifact.com/factchecks/2008/jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>false</td>\n",
       "      <td>Matt Gaetz</td>\n",
       "      <td>\"Bennie Thompson actively cheer-led riots in t...</td>\n",
       "      <td>6/7/2022</td>\n",
       "      <td>television</td>\n",
       "      <td>Yacob Reyes</td>\n",
       "      <td>6/13/2022</td>\n",
       "      <td>https://www.politifact.com/factchecks/2022/jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Kelly Ayotte</td>\n",
       "      <td>Says Maggie Hassan was \"out of state on 30 day...</td>\n",
       "      <td>5/18/2016</td>\n",
       "      <td>news</td>\n",
       "      <td>Clay Wirestone</td>\n",
       "      <td>5/27/2016</td>\n",
       "      <td>https://www.politifact.com/factchecks/2016/may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Bloggers</td>\n",
       "      <td>\"BUSTED: CDC Inflated COVID Numbers, Accused o...</td>\n",
       "      <td>2/1/2021</td>\n",
       "      <td>blog</td>\n",
       "      <td>Madison Czopek</td>\n",
       "      <td>2/5/2021</td>\n",
       "      <td>https://www.politifact.com/factchecks/2021/feb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>Bobby Jindal</td>\n",
       "      <td>\"I'm the only (Republican) candidate that has ...</td>\n",
       "      <td>8/30/2015</td>\n",
       "      <td>television</td>\n",
       "      <td>Linda Qiu</td>\n",
       "      <td>8/30/2015</td>\n",
       "      <td>https://www.politifact.com/factchecks/2015/aug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       verdict statement_originator  \\\n",
       "0         true         Barack Obama   \n",
       "1        false           Matt Gaetz   \n",
       "2  mostly-true         Kelly Ayotte   \n",
       "3        false             Bloggers   \n",
       "4    half-true         Bobby Jindal   \n",
       "\n",
       "                                           statement statement_date  \\\n",
       "0  John McCain opposed bankruptcy protections for...      6/11/2008   \n",
       "1  \"Bennie Thompson actively cheer-led riots in t...       6/7/2022   \n",
       "2  Says Maggie Hassan was \"out of state on 30 day...      5/18/2016   \n",
       "3  \"BUSTED: CDC Inflated COVID Numbers, Accused o...       2/1/2021   \n",
       "4  \"I'm the only (Republican) candidate that has ...      8/30/2015   \n",
       "\n",
       "  statement_source        factchecker factcheck_date  \\\n",
       "0           speech  Adriel Bettelheim      6/16/2008   \n",
       "1       television        Yacob Reyes      6/13/2022   \n",
       "2             news     Clay Wirestone      5/27/2016   \n",
       "3             blog     Madison Czopek       2/5/2021   \n",
       "4       television          Linda Qiu      8/30/2015   \n",
       "\n",
       "                             factcheck_analysis_link  \n",
       "0  https://www.politifact.com/factchecks/2008/jun...  \n",
       "1  https://www.politifact.com/factchecks/2022/jun...  \n",
       "2  https://www.politifact.com/factchecks/2016/may...  \n",
       "3  https://www.politifact.com/factchecks/2021/feb...  \n",
       "4  https://www.politifact.com/factchecks/2015/aug...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21152, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verdict\n",
       "false           5625\n",
       "half-true       3597\n",
       "mostly-false    3432\n",
       "mostly-true     3332\n",
       "pants-fire      2703\n",
       "true            2463\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.verdict.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarise the labels\n",
    "binary_map = {\n",
    "    'true': 1,\n",
    "    'mostly-true': 1, \n",
    "    'half-true': 1,\n",
    "    'mostly-false': 0,\n",
    "    'false': 0,\n",
    "    'pants-fire': 0 \n",
    "}\n",
    "\n",
    "df['binary_verdict'] = df['verdict'].map(binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Clean the dataset\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove punctuation and remove words containing numbers.'''\n",
    "    # text = text.lower()\n",
    "    # text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # text = re.sub('\\n', '', text)\n",
    "    # text = re.sub('[0-9]+', '', text)\n",
    "    # text = re.sub(r\" +\", \" \", text)\n",
    "    text = re.sub('\\u00a0', ' ', text)\n",
    "    text = re.sub('\\u2019', '\\'', text)\n",
    "    text = re.sub('\\u2018', '\\'', text)\n",
    "    # text = re.sub('\\u2019', '', text)\n",
    "    # text = re.sub('\\u2018', '', text)\n",
    "    # text = re.sub('\\u2026', '', text)\n",
    "    # text = re.sub('\\u2013', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_spaces(text):\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_statement'] = df['statement'].apply(clean_text)\n",
    "#df['cleaned_statement'] = df['cleaned_statement'].apply(remove_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verdict</th>\n",
       "      <th>statement_originator</th>\n",
       "      <th>statement</th>\n",
       "      <th>statement_date</th>\n",
       "      <th>statement_source</th>\n",
       "      <th>factchecker</th>\n",
       "      <th>factcheck_date</th>\n",
       "      <th>factcheck_analysis_link</th>\n",
       "      <th>binary_verdict</th>\n",
       "      <th>cleaned_statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>John McCain opposed bankruptcy protections for...</td>\n",
       "      <td>6/11/2008</td>\n",
       "      <td>speech</td>\n",
       "      <td>Adriel Bettelheim</td>\n",
       "      <td>6/16/2008</td>\n",
       "      <td>https://www.politifact.com/factchecks/2008/jun...</td>\n",
       "      <td>1</td>\n",
       "      <td>John McCain opposed bankruptcy protections for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>false</td>\n",
       "      <td>Matt Gaetz</td>\n",
       "      <td>\"Bennie Thompson actively cheer-led riots in t...</td>\n",
       "      <td>6/7/2022</td>\n",
       "      <td>television</td>\n",
       "      <td>Yacob Reyes</td>\n",
       "      <td>6/13/2022</td>\n",
       "      <td>https://www.politifact.com/factchecks/2022/jun...</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Bennie Thompson actively cheer-led riots in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Kelly Ayotte</td>\n",
       "      <td>Says Maggie Hassan was \"out of state on 30 day...</td>\n",
       "      <td>5/18/2016</td>\n",
       "      <td>news</td>\n",
       "      <td>Clay Wirestone</td>\n",
       "      <td>5/27/2016</td>\n",
       "      <td>https://www.politifact.com/factchecks/2016/may...</td>\n",
       "      <td>1</td>\n",
       "      <td>Says Maggie Hassan was \"out of state on 30 day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Bloggers</td>\n",
       "      <td>\"BUSTED: CDC Inflated COVID Numbers, Accused o...</td>\n",
       "      <td>2/1/2021</td>\n",
       "      <td>blog</td>\n",
       "      <td>Madison Czopek</td>\n",
       "      <td>2/5/2021</td>\n",
       "      <td>https://www.politifact.com/factchecks/2021/feb...</td>\n",
       "      <td>0</td>\n",
       "      <td>\"BUSTED: CDC Inflated COVID Numbers, Accused o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>Bobby Jindal</td>\n",
       "      <td>\"I'm the only (Republican) candidate that has ...</td>\n",
       "      <td>8/30/2015</td>\n",
       "      <td>television</td>\n",
       "      <td>Linda Qiu</td>\n",
       "      <td>8/30/2015</td>\n",
       "      <td>https://www.politifact.com/factchecks/2015/aug...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I'm the only (Republican) candidate that has ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       verdict statement_originator  \\\n",
       "0         true         Barack Obama   \n",
       "1        false           Matt Gaetz   \n",
       "2  mostly-true         Kelly Ayotte   \n",
       "3        false             Bloggers   \n",
       "4    half-true         Bobby Jindal   \n",
       "\n",
       "                                           statement statement_date  \\\n",
       "0  John McCain opposed bankruptcy protections for...      6/11/2008   \n",
       "1  \"Bennie Thompson actively cheer-led riots in t...       6/7/2022   \n",
       "2  Says Maggie Hassan was \"out of state on 30 day...      5/18/2016   \n",
       "3  \"BUSTED: CDC Inflated COVID Numbers, Accused o...       2/1/2021   \n",
       "4  \"I'm the only (Republican) candidate that has ...      8/30/2015   \n",
       "\n",
       "  statement_source        factchecker factcheck_date  \\\n",
       "0           speech  Adriel Bettelheim      6/16/2008   \n",
       "1       television        Yacob Reyes      6/13/2022   \n",
       "2             news     Clay Wirestone      5/27/2016   \n",
       "3             blog     Madison Czopek       2/5/2021   \n",
       "4       television          Linda Qiu      8/30/2015   \n",
       "\n",
       "                             factcheck_analysis_link  binary_verdict  \\\n",
       "0  https://www.politifact.com/factchecks/2008/jun...               1   \n",
       "1  https://www.politifact.com/factchecks/2022/jun...               0   \n",
       "2  https://www.politifact.com/factchecks/2016/may...               1   \n",
       "3  https://www.politifact.com/factchecks/2021/feb...               0   \n",
       "4  https://www.politifact.com/factchecks/2015/aug...               1   \n",
       "\n",
       "                                   cleaned_statement  \n",
       "0  John McCain opposed bankruptcy protections for...  \n",
       "1  \"Bennie Thompson actively cheer-led riots in t...  \n",
       "2  Says Maggie Hassan was \"out of state on 30 day...  \n",
       "3  \"BUSTED: CDC Inflated COVID Numbers, Accused o...  \n",
       "4  \"I'm the only (Republican) candidate that has ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# get the sample dataset\n",
    "class PolitifactDataset(Dataset):\n",
    "    def __init__(self, text, originator, labels):\n",
    "        self.labels = labels.values\n",
    "        self.text = text.values\n",
    "        self.originator = originator.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        text = self.text[idx]\n",
    "        originator = self.originator[idx] \n",
    "\n",
    "        sample = (label, text, originator)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_label = PolitifactDataset(df[\"statement\"],\n",
    "                            df[\"statement_originator\"],\n",
    "                            df[\"binary_verdict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originator: Barack Obama\n",
      "Text: John McCain opposed bankruptcy protections for families \"who were only in bankruptcy because of medical expenses they couldn't pay.\"\n",
      "Label: 1\n",
      "\n",
      "Length of dataset:  21152 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the first element\n",
    "first_element = next(iter(dataset_label))\n",
    "\n",
    "first_element = next(iter(dataset_label))\n",
    "print(f\"Originator: {first_element[2]}\")\n",
    "print(f\"Text: {first_element[1]}\")\n",
    "print(f\"Label: {first_element[0]}\\n\")\n",
    "\n",
    "# Length of dataset\n",
    "print('Length of dataset: ', len(dataset_label), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset saved as Datasets\\PolitiFact\\PolitiFact_Clean.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Convert dataset_label into a JSON serialisable format\n",
    "dataset_json = [\n",
    "    {\"statement\": statement, \"originator\": originator, \"label\": label}\n",
    "    for statement, originator, label in zip(df[\"statement\"], df[\"statement_originator\"], df[\"binary_verdict\"])\n",
    "]\n",
    "\n",
    "# Save as JSON file\n",
    "json_filename = r'Datasets\\PolitiFact\\PolitiFact_Clean.json'\n",
    "with open(json_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(dataset_json, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Dataset saved as {json_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset For Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PolitiFact_Fine_Tuning.jsonl.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load full dataset\n",
    "with open(r'Datasets\\PolitiFact\\PolitiFact_Clean.json', 'r', encoding=\"utf-8\") as f:\n",
    "    data_ft = json.load(f)\n",
    "\n",
    "# Convert into desired format\n",
    "converted_data = []\n",
    "for entry in data_ft:\n",
    "    text = f'{entry[\"originator\"]} says: {entry[\"statement\"]}'\n",
    "    label = entry[\"label\"]\n",
    "    converted_data.append({\n",
    "        \"text\": text,\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "# Save to JSONL\n",
    "with open(r'Datasets\\PolitiFact\\PolitiFact_Fine_Tuning.jsonl', 'w', encoding=\"utf-8\") as f:\n",
    "    for entry in converted_data:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(\"Saved PolitiFact_Fine_Tuning.jsonl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset converted to prompt-completion format.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load existing datapoint dataset\n",
    "with open(r\"Datasets\\PolitiFact\\PolitiFact_Fine_Tuning.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    original_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Convert into prompt-completion format, first 5000 entries\n",
    "prompt_completion_data = []\n",
    "for entry in original_data[:5000]:\n",
    "    text = entry[\"text\"]\n",
    "    label = \"True\" if entry[\"label\"] == 1 else \"False\"\n",
    "\n",
    "    prompt = f\"'{text}'\\nIs this claim True or False?\"\n",
    "    completion = f\"The claim is {label}\"\n",
    "\n",
    "    prompt_completion_data.append({\"prompt\": prompt, \"completion\": completion})\n",
    "\n",
    "# Save the new format\n",
    "with open(r\"Datasets\\PolitiFact\\PolitiFact_PromptCompletion.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in prompt_completion_data:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(\"✅ Dataset converted to prompt-completion format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset converted to prompt-completion format.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load your existing datapoint dataset\n",
    "with open(r\"Datasets\\PolitiFact\\PolitiFact_Fine_Tuning.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    original_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Convert into prompt-completion format entries 5000-6000\n",
    "prompt_completion_data = []\n",
    "for entry in original_data[5000:6000]:\n",
    "    text = entry[\"text\"]\n",
    "    label = \"True\" if entry[\"label\"] == 1 else \"False\"\n",
    "\n",
    "    prompt = f\"'{text}'\\nIs this claim True or False?\"\n",
    "    completion = f\"{label}\"\n",
    "\n",
    "    prompt_completion_data.append({\"prompt\": prompt, \"completion\": completion})\n",
    "\n",
    "# Save the new format\n",
    "with open(r\"Datasets\\PolitiFact_PromptCompletion_Test.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in prompt_completion_data:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(\"✅ Dataset converted to prompt-completion format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'False': 55, 'True': 45})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "with open(r'Datasets\\PolitiFact_PromptCompletion_Test.jsonl', 'r', encoding=\"utf-8\") as f:\n",
    "    datas = [json.loads(line) for line in f]\n",
    "\n",
    "datas = datas[:100]\n",
    "# Extract labels and count\n",
    "label_counts = Counter(entry['completion'] for entry in datas)\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset converted to Alpaca format and saved at: Datasets\\PolitiFact_Alpaca.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Define input and output file paths\n",
    "input_path = r\"Datasets\\PolitiFact\\PolitiFact_PromptCompletion.jsonl\"\n",
    "output_path = r\"Datasets\\PolitiFact_Alpaca.json\"\n",
    "\n",
    "# Load the dataset from JSONL\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Convert dataset to Alpaca format\n",
    "alpaca_dataset = []\n",
    "\n",
    "for entry in dataset:\n",
    "    # Extract the full prompt and completion\n",
    "    full_prompt = entry.get(\"prompt\", \"\").strip()\n",
    "    completion = entry.get(\"completion\", \"\").strip()\n",
    "\n",
    "    # Split the full prompt into \"instruction\" & \"input\"\n",
    "    if \"\\n\" in full_prompt:  \n",
    "        instruction, input_text = full_prompt.split(\"\\n\", 1)\n",
    "        input_text = input_text.strip()\n",
    "    else:\n",
    "        instruction = full_prompt  \n",
    "        input_text = \"\"\n",
    "\n",
    "    # Remove unnecessary surrounding quotes from instruction\n",
    "    instruction = re.sub(r\"^['\\\"]|['\\\"]$\", \"\", instruction).strip()\n",
    "\n",
    "    # Create an Alpaca-style dictionary\n",
    "    alpaca_entry = {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": input_text,\n",
    "        \"output\": completion\n",
    "    }\n",
    "\n",
    "    alpaca_dataset.append(alpaca_entry)\n",
    "\n",
    "# Save the new dataset as JSON\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(alpaca_dataset, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Dataset converted to Alpaca format and saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset converted to Alpaca format and saved at: Datasets\\PolitiFact_Alpaca_Test.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Define input and output file paths\n",
    "input_path = r\"Datasets\\PolitiFact_PromptCompletion_Test.jsonl\"\n",
    "output_path = r\"Datasets\\PolitiFact_Alpaca_Test.json\"\n",
    "\n",
    "# Load the dataset from JSONL\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Convert dataset to Alpaca format\n",
    "alpaca_dataset = []\n",
    "\n",
    "for entry in dataset:\n",
    "    # Extract the full prompt and completion\n",
    "    full_prompt = entry.get(\"prompt\", \"\").strip()\n",
    "    completion = entry.get(\"completion\", \"\").strip()\n",
    "\n",
    "    # Split the full prompt into \"instruction\" & \"input\"\n",
    "    if \"\\n\" in full_prompt:  \n",
    "        instruction, input_text = full_prompt.split(\"\\n\", 1)\n",
    "        input_text = input_text.strip()\n",
    "    else:\n",
    "        instruction = full_prompt  \n",
    "        input_text = \"\"\n",
    "\n",
    "    # Remove unnecessary surrounding quotes from instruction\n",
    "    instruction = re.sub(r\"^['\\\"]|['\\\"]$\", \"\", instruction).strip()\n",
    "\n",
    "    # Create an Alpaca-style dictionary\n",
    "    alpaca_entry = {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": input_text,\n",
    "        \"output\": completion\n",
    "    }\n",
    "\n",
    "    alpaca_dataset.append(alpaca_entry)\n",
    "\n",
    "# Save the new dataset as JSON\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(alpaca_dataset, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Dataset converted to Alpaca format and saved at: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
