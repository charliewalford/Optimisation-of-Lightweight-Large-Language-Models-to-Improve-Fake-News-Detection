{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 1)) (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: seaborn in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 3)) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 4)) (3.7.5)\n",
      "Requirement already satisfied: gensim in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 5)) (4.3.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 6)) (3.9.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 7)) (2.18.0)\n",
      "Requirement already satisfied: torch in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: torchtext==0.15.2 in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 9)) (0.15.2)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 10)) (1.6.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: keras in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 12)) (3.8.0)\n",
      "Requirement already satisfied: keras_balanced_batch_generator in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 13)) (0.0.3)\n",
      "Requirement already satisfied: ipython in c:\\users\\charl\\appdata\\roaming\\python\\python310\\site-packages (from -r Requirements.txt (line 14)) (8.32.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\charl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r Requirements.txt (line 15)) (3.8.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tranformers (from versions: none)\n",
      "ERROR: No matching distribution found for tranformers\n"
     ]
    }
   ],
   "source": [
    "%pip install -r Requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factbox: Trump on Twitter (July 24) - Chuck Sc...</td>\n",
       "      <td>The following statements were posted to the ve...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 25, 2017</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump shows his presidential bid is no mere pu...</td>\n",
       "      <td>MANCHESTER, N.H. (Reuters) - Donald Trump serv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 10, 2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinton Campaign Attack Dog Warns Trump And Sa...</td>\n",
       "      <td>Hey, everything is fair game in this war to wi...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Jan 11, 2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FULL SPEECH: Trump Rocks South Carolina With A...</td>\n",
       "      <td>A record crowd In Anderson, SC last night for ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Oct 20, 2015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. may need new law to address Russian ad bu...</td>\n",
       "      <td>WASHINGTON/SAN FRANCISCO (Reuters) - U.S. legi...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>September 7, 2017</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Factbox: Trump on Twitter (July 24) - Chuck Sc...   \n",
       "1  Trump shows his presidential bid is no mere pu...   \n",
       "2  Clinton Campaign Attack Dog Warns Trump And Sa...   \n",
       "3  FULL SPEECH: Trump Rocks South Carolina With A...   \n",
       "4  U.S. may need new law to address Russian ad bu...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  The following statements were posted to the ve...  politicsNews   \n",
       "1  MANCHESTER, N.H. (Reuters) - Donald Trump serv...  politicsNews   \n",
       "2  Hey, everything is fair game in this war to wi...      politics   \n",
       "3  A record crowd In Anderson, SC last night for ...      politics   \n",
       "4  WASHINGTON/SAN FRANCISCO (Reuters) - U.S. legi...  politicsNews   \n",
       "\n",
       "                 date Target  \n",
       "0      July 25, 2017    True  \n",
       "1  February 10, 2016    True  \n",
       "2        Jan 11, 2016  False  \n",
       "3        Oct 20, 2015  False  \n",
       "4  September 7, 2017    True  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# Load Dataset\n",
    "true_data = pd.read_csv(r'Datasets\\Fake_or_Real_News\\True.csv')\n",
    "fake_data = pd.read_csv(r'Datasets\\Fake_or_Real_News\\Fake.csv')\n",
    "\n",
    "# Generate labels True/Fake under new Target Column in 'true_data' and 'fake_data'\n",
    "true_data['Target'] = ['True']*len(true_data)\n",
    "fake_data['Target'] = ['False']*len(fake_data)\n",
    "\n",
    "\n",
    "# Merge 'true_data' and 'fake_data', by random mixing into a single df called 'data'\n",
    "df = pd.concat([true_data, fake_data]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# See how the data looks like\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and transformed CSV saved at: Datasets\\Fake_or_Real_News\\FakeorReal_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Create the transformed DataFrame\n",
    "df_transformed = pd.DataFrame({\n",
    "    'instruction': df['title'], \n",
    "    'input': 'Is this claim True or False?',\n",
    "    'output': df['Target']\n",
    "})\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_path = r'Datasets\\Fake_or_Real_News\\FakeorReal_clean.csv'\n",
    "df_transformed.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned and transformed CSV saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON saved at: Datasets\\FakeorReal_Alpaca_Test.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned CSV file\n",
    "csv_file_path = r'Datasets\\Fake_or_Real_News\\FakeorReal_clean.csv'  # Update the path if needed\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Ensure 'output' column is treated as a string\n",
    "df['output'] = df['output'].astype(str)\n",
    "\n",
    "# Convert DataFrame to JSON format\n",
    "json_file_path = r'Datasets\\FakeorReal_Alpaca_Test.json'  # Define output JSON file path\n",
    "df.to_json(json_file_path, orient='records', indent=4, force_ascii=False)\n",
    "\n",
    "print(f\"Converted JSON saved at: {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'False': 55, 'True': 45})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "with open(r'Datasets\\FakeorReal_Alpaca_Test.json', 'r', encoding=\"utf-8\") as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "datas = datas[:100]\n",
    "# Extract labels and count\n",
    "label_counts = Counter(entry['output'] for entry in datas)\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Saved as Datasets\\FakeorReal_PromptCompletion_Test.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Input and output file paths\n",
    "json_file_path = \"Datasets\\FakeorReal_Alpaca_Test.json\"  \n",
    "jsonl_file_path = \"Datasets\\FakeorReal_PromptCompletion_Test.jsonl\" \n",
    "\n",
    "# Load JSON data\n",
    "with open(json_file_path, mode='r', encoding='utf-8') as json_file:\n",
    "    data = json.load(json_file) \n",
    "\n",
    "# Open the JSONL file for writing\n",
    "with open(jsonl_file_path, mode='w', encoding='utf-8') as jsonl_file:\n",
    "    for entry in data:\n",
    "        # Construct the new format\n",
    "        json_entry = {\n",
    "            \"prompt\": f\"'{entry['instruction']}'\\n{entry['input']}\",\n",
    "            \"completion\": entry['output']\n",
    "        }\n",
    "        # Write to JSONL file\n",
    "        jsonl_file.write(json.dumps(json_entry) + \"\\n\")\n",
    "\n",
    "print(f\"Conversion complete! Saved as {jsonl_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
